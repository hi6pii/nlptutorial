{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 確率的言語モデル"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数学記号\n",
    "- 総乗 $ \\prod_{ a }^{b } $\n",
    "- バーティカルバー \n",
    "    - 絶対値 |x|\n",
    "    - 単語数 |W|\n",
    "    - 条件付き確率 P(A|B)\n",
    "    - 定義 {x | x<2}\n",
    "- 約 $ \\approx $\n",
    "- 中央値 $ \\tilde{w} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 言語モデル\n",
    "- 言語モデルが各文(W)に確率を与える  \n",
    "W = speech recognition system\n",
    "- 変数で以下のようにあらわす  \n",
    "P(|W|=3, w1=\"speech\", w2=\"recognition\", w3=\"system\")\n",
    "- 文の確率がほしい **総乗**\n",
    "\n",
    ">P(|W|=3, w1=\"speech\", w2=\"recognition\", w3=\"system\") =   \n",
    " P(w1=\"speech\"|w_0=\"<\\s>\")  \n",
    " x P(w2=\"recognition\" | w_0=\"<\\s>\", w_1=\"speech\")  \n",
    " x P(w3=\"system\" | w_0=\"<\\s>\", w_1=\"speech\", w_2=\"recognition\")  \n",
    " x P(w4=\"<\\s>\" | w_0=\"<\\s>\", w_1=\"speech\", w_2=\"recognition\", w3=\"system\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定義：\n",
    "- 確率の漸次的(ぜんじ、しだいに）な計算：\n",
    "$$ P(W)= \\prod_{ i =1 }^{ |W|+1 } P(w_i∣w_0…w_{i−1}) $$\n",
    "- 条件付き確率の決め方は？\n",
    "$$ P(w_i|w_0 ... w_{i-1}) $$  \n",
    "- 最尤推定: コーパスの単語列を数え上げて割ることで計算\n",
    "$$ P(w_i|w_0 ... w_{i-1}) = \\frac{c(w_1 ... w_i)}{c_(w_1 ... w_{i-1})} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1-gram モデル\n",
    "- 履歴を用いないことで低頻度の現象を減らす\n",
    "  - approx(約), tilde(中央値)\n",
    "$$ P(w_i|w_0 ... w_{i-1}) \\approx P(wi) = \\frac{c(w_i)}{\\sum_{ \\tilde{w} }^{  } c(\\tilde{w})} $$\n",
    "- 未知語への対応\n",
    "  - 多くの場合、無視される\n",
    "  - 少しの確率を未知語に割り当てる  $ \\lambda_{unk} = 1- \\lambda_1 $\n",
    "  - 未知語を含む語彙数 N  例えば$ N= 10^6 $\n",
    "  $ P(w_i) = \\lambda_1P_{ML}(w_i)+(1-\\lambda_1)\\frac{1}{N} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルの評価\n",
    "- 尤度（ゆうど）: モデルMが与えられた時の観測されたデータの確率\n",
    "$$ P(W_{test} | M) = \\prod_{w \\in w_{test}}^{ } P(w|M) $$\n",
    "- 対数尤度: 尤度を対数にすることで桁あふれを解決\n",
    "$$ \\log P(W_{test} | M) = \\prod_{w \\in w_{test}}^{ } \\log P(w|M) $$\n",
    "- エントロピー H: 負の底2の対数尤度を単語数で割った値\n",
    "$$ H(W_{test} | M) = \\frac {1}{|W_{test}|} \\prod_{w \\in w_{test}}^{ } \\ -log_2 P(w|M) $$\n",
    "- パープレキシティ: 2のエントロピー乗\n",
    "$$ PPL = 2^H $$\n",
    "- カバレージ：評価データに現れた単語（n-gram)の中でモデルに含まれている割合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_words(lines):\n",
    "    total_count = 0\n",
    "    counts = {}\n",
    "    for line in lines:\n",
    "        words = line.strip().split()\n",
    "        words.append(\"</s>\")\n",
    "        for word in words:\n",
    "            counts[word] = counts.get(word, 0) + 1\n",
    "            total_count += 1\n",
    "    return total_count, counts\n",
    "\n",
    "def build_model(counts, total_count):\n",
    "    probabilities = {}\n",
    "    for word, count in counts.items():\n",
    "        probability = counts[word] / total_count\n",
    "        probabilities[word] = probability\n",
    "    return probabilities\n",
    "\n",
    "def use_model(model, counts):\n",
    "    probabilities = {}\n",
    "    for word, _ in counts.items():\n",
    "        probabilities[word] = model.get(word, 0)\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'b': 0.25, 'c': 0.125, 'd': 0.125, '</s>': 0.25, 'a': 0.25}\n"
     ]
    }
   ],
   "source": [
    "# build model\n",
    "with open('01-train-input.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "total_count, counts = count_words(lines)\n",
    "model = build_model(counts, total_count)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'e': 0, 'c': 0.125, '</s>': 0.25, 'a': 0.25}\n"
     ]
    }
   ],
   "source": [
    "# use model\n",
    "with open('01-test-input.txt') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "total_count, counts = count_words(lines)\n",
    "probabilities = use_model(model, counts)\n",
    "print(probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# build model\n",
    "with open('../data/wiki-en-train.word', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "total_count, counts = count_words(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'texts': 17,\n",
       " 'automatizing': 1,\n",
       " 'deploy': 1,\n",
       " 'easy': 3,\n",
       " 'loud': 1,\n",
       " 'availability': 1,\n",
       " 'isloated': 1,\n",
       " 'letter': 6,\n",
       " 'SpeechTEK': 2,\n",
       " 'among': 8,\n",
       " 'gaming': 1,\n",
       " 'impossible': 2,\n",
       " 'simplification': 1,\n",
       " 'polynomial-size': 1,\n",
       " 'multitude': 1,\n",
       " 'compactly': 1,\n",
       " 'encoding': 1,\n",
       " 'masculine': 1,\n",
       " 'reports': 5,\n",
       " '1997': 2,\n",
       " 'cosine': 3,\n",
       " 'crossed': 1,\n",
       " 'Clancy': 1,\n",
       " ':': 102,\n",
       " 'limiting': 1,\n",
       " 'MIT': 2,\n",
       " 'Translator': 1,\n",
       " 'relief': 1,\n",
       " 'improvements': 2,\n",
       " 'modeling': 7,\n",
       " 'Commissioned': 1,\n",
       " 'progress': 7,\n",
       " 'Variation': 1,\n",
       " 'valid': 1,\n",
       " 'transformations': 2,\n",
       " 'characterize': 2,\n",
       " 'devices': 4,\n",
       " '1953': 1,\n",
       " 'closed-captioning': 1,\n",
       " 'interoperability': 1,\n",
       " 'spelled': 1,\n",
       " 'pattern': 6,\n",
       " 'contextual': 2,\n",
       " 'meantime': 1,\n",
       " 'test': 10,\n",
       " 'seek': 1,\n",
       " 'anymore': 1,\n",
       " 'Lauriault\\\\/Loriot': 2,\n",
       " 'experimented': 1,\n",
       " 'fashion': 1,\n",
       " 'demonstration': 5,\n",
       " 'storing': 1,\n",
       " 'distinctive': 2,\n",
       " 'commercially': 2,\n",
       " 'studying': 1,\n",
       " 'alignment': 2,\n",
       " 'capitalizes': 1,\n",
       " 'and': 692,\n",
       " 'able': 16,\n",
       " 'foreign': 2,\n",
       " 'consisting': 2,\n",
       " 'cohesion': 1,\n",
       " 'wrote': 6,\n",
       " 'Online': 2,\n",
       " 'stating': 1,\n",
       " 'British': 3,\n",
       " 'wishes': 1,\n",
       " 'frame': 2,\n",
       " 'positives': 1,\n",
       " 'night': 1,\n",
       " 'construction': 3,\n",
       " 'ATIS': 1,\n",
       " 'Digital': 1,\n",
       " 'Engineers': 2,\n",
       " 'Marc': 1,\n",
       " 'fragments': 1,\n",
       " 'undercarriage': 1,\n",
       " 'Although': 8,\n",
       " 'biographical': 1,\n",
       " 'politics': 1,\n",
       " 'Automatic': 9,\n",
       " 'MySpace': 1,\n",
       " 'concatenating': 1,\n",
       " 'challenging': 1,\n",
       " 'overall': 6,\n",
       " 'uh': 1,\n",
       " 'Slembrouck': 1,\n",
       " 'authenticate': 1,\n",
       " 'voices': 1,\n",
       " 'fairly': 4,\n",
       " 'analysis': 65,\n",
       " 'Tauschek': 2,\n",
       " 'Throughout': 1,\n",
       " 'statically': 1,\n",
       " 'services': 3,\n",
       " 'portions': 1,\n",
       " '2005': 1,\n",
       " 'information': 46,\n",
       " 'most': 58,\n",
       " 'representing': 2,\n",
       " 'acquire': 1,\n",
       " 'sociology': 1,\n",
       " 'burden': 1,\n",
       " 'return': 2,\n",
       " 'pre-defined': 2,\n",
       " 'garden-path': 1,\n",
       " 'cockpit': 2,\n",
       " 'shallow': 6,\n",
       " 'Jonathan': 1,\n",
       " 'unseen': 1,\n",
       " 'innumerable': 1,\n",
       " 'morphology': 7,\n",
       " 'clues': 3,\n",
       " 'conduct': 1,\n",
       " 'entities': 7,\n",
       " 'disambiguate': 3,\n",
       " 'Reading': 2,\n",
       " 'further': 8,\n",
       " 'happen': 1,\n",
       " 'discover': 1,\n",
       " 'uninterrupted': 1,\n",
       " 'structure': 12,\n",
       " 'paragraph': 3,\n",
       " 'alone': 4,\n",
       " 'mid': 1,\n",
       " 'Dependence': 1,\n",
       " 'similarities': 2,\n",
       " 'due': 5,\n",
       " 'Lakoff': 1,\n",
       " 'arbitrary': 3,\n",
       " 'up-to-date': 1,\n",
       " 'posts': 1,\n",
       " 'task-based': 4,\n",
       " 'et': 1,\n",
       " '1957': 1,\n",
       " 'Jay': 1,\n",
       " 'interpreted': 1,\n",
       " 'attempt': 6,\n",
       " 'dictionary-based': 1,\n",
       " 'time-scales': 1,\n",
       " 'came': 2,\n",
       " 'passage': 1,\n",
       " 'regardless': 3,\n",
       " 'dimensionality': 1,\n",
       " 'fast-evolving': 1,\n",
       " 'nice': 4,\n",
       " 'intelligent': 1,\n",
       " 'Grace': 1,\n",
       " 'candidacies': 1,\n",
       " 'array': 1,\n",
       " '1930s': 1,\n",
       " 'Modern': 3,\n",
       " 'They': 3,\n",
       " 'interpreters': 1,\n",
       " 'tests': 4,\n",
       " 'some': 83,\n",
       " 'opportunities': 1,\n",
       " ',': 1781,\n",
       " 'can': 181,\n",
       " 'finalized': 1,\n",
       " 'terminate': 1,\n",
       " '2012': 1,\n",
       " 'ground': 1,\n",
       " 'playing': 1,\n",
       " 'If': 10,\n",
       " 'Activity': 1,\n",
       " 'categorical': 1,\n",
       " 'considered': 9,\n",
       " 'speeches': 1,\n",
       " 'hyphenation': 1,\n",
       " '20,000': 1,\n",
       " 'critical': 4,\n",
       " 'evaluators': 1,\n",
       " 'proceedings': 1,\n",
       " 'Black-box': 2,\n",
       " 'memory': 2,\n",
       " 'constructs': 3,\n",
       " 'phoneme': 2,\n",
       " 'stationary': 7,\n",
       " 'Document': 4,\n",
       " '32': 1,\n",
       " 'reference': 8,\n",
       " 'Inclusive': 1,\n",
       " 'removing': 2,\n",
       " 'Genres': 1,\n",
       " 'enormous': 1,\n",
       " 'corrected': 1,\n",
       " 'clean': 2,\n",
       " 'summarization': 50,\n",
       " 'structures': 5,\n",
       " '1994': 1,\n",
       " 'Swedish': 1,\n",
       " 'Some': 21,\n",
       " 'Understanding': 2,\n",
       " 'different': 49,\n",
       " 'graphics': 1,\n",
       " 'Pronunciation': 1,\n",
       " 'followed': 4,\n",
       " 'Ingria': 1,\n",
       " 'soon': 3,\n",
       " 'Grass': 4,\n",
       " 'pitch': 1,\n",
       " 'dismiss': 1,\n",
       " 'captioning': 1,\n",
       " 'multiplying': 1,\n",
       " 'POS': 13,\n",
       " 'normal': 2,\n",
       " 'post-processing': 3,\n",
       " 'detailed': 2,\n",
       " 'forums': 1,\n",
       " 'Consultant': 1,\n",
       " 'opposed': 1,\n",
       " 'machine': 79,\n",
       " 'equivalent': 5,\n",
       " 'accomplish': 1,\n",
       " '9': 1,\n",
       " 'Digest': 3,\n",
       " 'explored': 2,\n",
       " 'photocells': 1,\n",
       " 'long-time': 1,\n",
       " 'connected': 5,\n",
       " 'preposition': 3,\n",
       " 'psycholinguistics': 2,\n",
       " 'observed': 1,\n",
       " 'Rules': 3,\n",
       " 'Tokens': 1,\n",
       " 'group': 4,\n",
       " 'DA': 3,\n",
       " 'campaigns': 2,\n",
       " 'breaks': 2,\n",
       " 'Speech': 31,\n",
       " 'rate': 11,\n",
       " 'trainer': 1,\n",
       " 'fire': 2,\n",
       " 'ensure': 1,\n",
       " 'SATZ': 1,\n",
       " 'NN': 1,\n",
       " 'situation': 2,\n",
       " 'disseminate': 1,\n",
       " 'query': 3,\n",
       " 'subjective': 6,\n",
       " 'stages': 2,\n",
       " 'Users': 1,\n",
       " 'pre': 1,\n",
       " 'Military': 1,\n",
       " 'numbers': 7,\n",
       " 'profile': 3,\n",
       " 'ARCHILES': 1,\n",
       " 'Approaches': 3,\n",
       " 'kept': 1,\n",
       " 'detected': 2,\n",
       " 'nodes': 7,\n",
       " 'accidentally': 1,\n",
       " 'male-female': 1,\n",
       " 'Glass-box': 1,\n",
       " 'contrast': 8,\n",
       " 'Statistical': 9,\n",
       " 'Unix': 2,\n",
       " 'On-line': 3,\n",
       " '`': 16,\n",
       " 'Subjectivity': 1,\n",
       " 'parametric': 1,\n",
       " 'transformed': 1,\n",
       " 'Sync': 1,\n",
       " 'unveiled': 1,\n",
       " 'non-textual': 1,\n",
       " '1-July-2005': 1,\n",
       " 'curves': 1,\n",
       " 'conventional': 1,\n",
       " 'rubric': 1,\n",
       " 'collaborated': 1,\n",
       " 'accepts': 2,\n",
       " '1983': 1,\n",
       " 'longest': 1,\n",
       " 'provides': 2,\n",
       " 'certainty': 1,\n",
       " 'rules': 43,\n",
       " 'Maximal': 1,\n",
       " 'full': 5,\n",
       " 'NER': 1,\n",
       " 'pronunciation': 1,\n",
       " 'unweighted': 1,\n",
       " 'AT&T': 1,\n",
       " 'eventually': 1,\n",
       " 'Components': 1,\n",
       " 'challenge': 1,\n",
       " 'eat': 1,\n",
       " 'II': 2,\n",
       " 'components': 5,\n",
       " 'Guzman': 1,\n",
       " 'positions': 1,\n",
       " 'for': 277,\n",
       " 'biomedical': 1,\n",
       " 'versus': 1,\n",
       " 'utility': 2,\n",
       " 'writing': 9,\n",
       " 'translated': 4,\n",
       " 'complex': 24,\n",
       " 'Brown': 14,\n",
       " 'efficient': 3,\n",
       " 'intra-texual': 1,\n",
       " 'heavy-noise': 1,\n",
       " 'solving': 1,\n",
       " 'survey': 1,\n",
       " 'proposed': 9,\n",
       " 'Ensemble': 1,\n",
       " 'constraint': 1,\n",
       " 'lexicon': 9,\n",
       " 'Sentence': 5,\n",
       " 'academic': 1,\n",
       " 'significantly': 1,\n",
       " 'coarse-grained': 1,\n",
       " 'That': 3,\n",
       " 'steadily': 1,\n",
       " 'tag': 16,\n",
       " 'native': 4,\n",
       " 'part': 27,\n",
       " 'decision': 4,\n",
       " 'Initial': 1,\n",
       " 'input-stream': 1,\n",
       " 'car': 1,\n",
       " 'Sept.': 1,\n",
       " 'People': 2,\n",
       " 'annotated': 2,\n",
       " 'undertake': 1,\n",
       " 'summers': 1,\n",
       " 'recursively': 2,\n",
       " 'discards': 1,\n",
       " 'fancy': 1,\n",
       " 'commanding': 1,\n",
       " 'English': 37,\n",
       " 'government': 3,\n",
       " 'perceptions': 1,\n",
       " 'Morse': 1,\n",
       " 'entropy-based': 1,\n",
       " 'Sager': 2,\n",
       " 'battle': 2,\n",
       " 'deal': 4,\n",
       " 'preferable': 1,\n",
       " '1946': 1,\n",
       " 'Army': 4,\n",
       " 'persuasion': 1,\n",
       " 'editor': 1,\n",
       " 'worldwide': 1,\n",
       " 'synthesis': 1,\n",
       " 'remarkably': 1,\n",
       " 'modules': 2,\n",
       " 'CKY': 1,\n",
       " '2500': 1,\n",
       " 'encouraged': 1,\n",
       " 'inter-texual': 2,\n",
       " 'interact': 1,\n",
       " 'John': 8,\n",
       " 'open-access': 1,\n",
       " 'Training': 2,\n",
       " 'Gaussians': 1,\n",
       " 'implicit': 1,\n",
       " 'outputs': 1,\n",
       " 'presentation': 1,\n",
       " 'extracted': 1,\n",
       " 'datum': 1,\n",
       " 'greater': 3,\n",
       " 'pronoun': 1,\n",
       " 'According': 1,\n",
       " 'ROUGE': 5,\n",
       " 'Elinor': 1,\n",
       " 'Systems': 12,\n",
       " 'class': 4,\n",
       " 'CSR': 3,\n",
       " 'matching': 5,\n",
       " 'rushing': 1,\n",
       " 'Optophone': 1,\n",
       " 'large': 23,\n",
       " 'pronunciations': 1,\n",
       " 'accompanying': 1,\n",
       " 'finite': 5,\n",
       " 'fastens': 1,\n",
       " 'weather': 7,\n",
       " 'BASEBALL': 2,\n",
       " 'relies': 1,\n",
       " 'Canada': 6,\n",
       " 'system-generated': 2,\n",
       " 'Environment': 1,\n",
       " 'Isles': 2,\n",
       " 'thousands': 3,\n",
       " 'democracy': 1,\n",
       " 'Pollen': 1,\n",
       " 'Air': 3,\n",
       " 'equivalence': 2,\n",
       " 'somehow': 1,\n",
       " 'UK': 4,\n",
       " 'had': 14,\n",
       " 'gained': 2,\n",
       " 'confusable': 1,\n",
       " 'observe': 1,\n",
       " 'Morphological': 1,\n",
       " 'exchange': 1,\n",
       " 'Aerospace': 2,\n",
       " 'consonants': 3,\n",
       " 'ARNS': 1,\n",
       " '2001': 2,\n",
       " 'Apart': 1,\n",
       " 'cope': 1,\n",
       " 'smoothly': 2,\n",
       " 'lowering': 1,\n",
       " 'draws': 1,\n",
       " 'predicted': 2,\n",
       " 'taking': 5,\n",
       " 'symbol': 4,\n",
       " 'Turkish': 1,\n",
       " 'starts': 2,\n",
       " 'hence': 2,\n",
       " 'latter': 1,\n",
       " 'supplying': 1,\n",
       " 'other': 70,\n",
       " 'explained': 1,\n",
       " 'measure': 11,\n",
       " 'conferences': 1,\n",
       " 'would': 53,\n",
       " 'routed': 2,\n",
       " 'five': 5,\n",
       " 'choose': 2,\n",
       " '15-20': 1,\n",
       " 'basic': 13,\n",
       " 'preceding': 1,\n",
       " 'anomalies': 1,\n",
       " 'timing': 1,\n",
       " 'crucial': 1,\n",
       " 'informal': 2,\n",
       " 'ATC': 5,\n",
       " 'compared': 7,\n",
       " 'Measuring': 1,\n",
       " 'LILOG': 2,\n",
       " 'toolkit': 2,\n",
       " 'SHRDLU': 6,\n",
       " 'incomplete': 1,\n",
       " 'divided': 3,\n",
       " 'cross-lingual': 2,\n",
       " 'sub-field': 1,\n",
       " 'scanned': 3,\n",
       " 'Development': 1,\n",
       " 'quoted': 1,\n",
       " 'checking': 1,\n",
       " 'Savic': 1,\n",
       " 'targets': 1,\n",
       " 'WebOCR': 4,\n",
       " 'well-defined': 1,\n",
       " 'league': 1,\n",
       " 'Guidelines': 2,\n",
       " 'lists': 1,\n",
       " 'task-effectiveness': 2,\n",
       " 'visible': 3,\n",
       " 'say': 7,\n",
       " 'postal': 1,\n",
       " 'Where': 1,\n",
       " 'programming': 5,\n",
       " 'merged': 1,\n",
       " 'values': 8,\n",
       " 'wide': 4,\n",
       " 'increasing': 3,\n",
       " 'collections': 4,\n",
       " 'review': 3,\n",
       " 'stub': 1,\n",
       " 'sold': 3,\n",
       " 'robotic': 1,\n",
       " 'context': 33,\n",
       " 'achieve': 2,\n",
       " 'maintained': 2,\n",
       " ';': 47,\n",
       " 'Machine': 9,\n",
       " 'assertive': 1,\n",
       " 'retrained': 1,\n",
       " 'turned': 2,\n",
       " 'such': 123,\n",
       " 'structured': 6,\n",
       " 'condense': 1,\n",
       " 'interjection': 1,\n",
       " 'world': 15,\n",
       " 'famous': 3,\n",
       " 'rescoring': 1,\n",
       " 'tables': 3,\n",
       " 'Further': 3,\n",
       " 'selling': 1,\n",
       " 'impossibility': 1,\n",
       " 'prisoner-of-war': 1,\n",
       " 'Its': 2,\n",
       " 'calculator': 2,\n",
       " 'ten-year-long': 1,\n",
       " 'dialog': 2,\n",
       " 'milliseconds': 2,\n",
       " 'Tannen': 1,\n",
       " 'makes': 8,\n",
       " 'Also': 3,\n",
       " 'digits': 1,\n",
       " 'Robinson': 1,\n",
       " 'integrate': 1,\n",
       " 'universal': 3,\n",
       " 'About': 2,\n",
       " '1,000,000': 1,\n",
       " 'Each': 6,\n",
       " 'specification': 2,\n",
       " 'sciences': 2,\n",
       " 'articulation': 1,\n",
       " 'Meaningful': 1,\n",
       " 'tense': 2,\n",
       " 'SPOTLIGHT': 1,\n",
       " 'founder': 1,\n",
       " 'Large-scale': 1,\n",
       " 'undertook': 1,\n",
       " 'straightforward': 1,\n",
       " 'judgement': 3,\n",
       " 'ones': 10,\n",
       " 'distorted': 2,\n",
       " 'NYU': 1,\n",
       " 'Evaluation': 9,\n",
       " 'lend': 1,\n",
       " 'just': 9,\n",
       " 'convey': 3,\n",
       " 'converts': 1,\n",
       " 'sizes': 3,\n",
       " 'requiring': 2,\n",
       " 'train': 1,\n",
       " 'TaleSpin': 1,\n",
       " 'time': 33,\n",
       " 'solutions': 2,\n",
       " 'successful': 9,\n",
       " 'States': 7,\n",
       " 'excess': 2,\n",
       " 'item': 1,\n",
       " 'abbreviations': 5,\n",
       " 'method': 16,\n",
       " 'resources': 6,\n",
       " 'assessed': 1,\n",
       " 'Z': 1,\n",
       " 'centres': 1,\n",
       " 'Accuracy': 7,\n",
       " 'offering': 1,\n",
       " 'Interactive': 2,\n",
       " 'Instead': 3,\n",
       " 'radios': 1,\n",
       " 'styles': 1,\n",
       " 'disappear': 1,\n",
       " 'decision-making': 1,\n",
       " 'computers': 9,\n",
       " 'varying': 1,\n",
       " 'transmitting': 1,\n",
       " 'but': 68,\n",
       " 'developments': 3,\n",
       " 'view': 3,\n",
       " 'succeeding': 1,\n",
       " 'Klavans': 1,\n",
       " 'Bobrow': 1,\n",
       " 'tackles': 1,\n",
       " 'Alternatively': 2,\n",
       " 'develop': 5,\n",
       " 'dependent': 3,\n",
       " 'layer': 3,\n",
       " 'state-of-the-art': 2,\n",
       " 'Profile': 1,\n",
       " 'tested': 2,\n",
       " 'Ratliff': 1,\n",
       " '40': 2,\n",
       " 'generally': 11,\n",
       " 'Archaeology': 1,\n",
       " 'stock': 3,\n",
       " 'coarticulation': 1,\n",
       " 'despite': 3,\n",
       " 'R.': 6,\n",
       " 'social': 14,\n",
       " 'Main': 12,\n",
       " 'semantically': 1,\n",
       " 'top-down': 4,\n",
       " 'teams': 2,\n",
       " 'like': 28,\n",
       " 'Rosa': 1,\n",
       " 'Act': 1,\n",
       " 'gestures': 2,\n",
       " 'maintenance': 1,\n",
       " 'Mutual': 1,\n",
       " 'Early': 2,\n",
       " 'success': 5,\n",
       " 'dBase': 1,\n",
       " 'validity': 1,\n",
       " 'common': 25,\n",
       " 'investigation': 1,\n",
       " 'hub': 1,\n",
       " 'focused': 11,\n",
       " 'orthography': 2,\n",
       " 'distinct': 7,\n",
       " 'descriptive': 3,\n",
       " 'governmental': 1,\n",
       " 'Contrary': 2,\n",
       " 'characterised': 1,\n",
       " 'primary': 2,\n",
       " 'affine': 1,\n",
       " 'rooms': 1,\n",
       " 'template-matching': 1,\n",
       " 'Relevance': 1,\n",
       " 'usability': 1,\n",
       " 'glass-box': 2,\n",
       " 'changes': 1,\n",
       " 'speaker-dependent': 1,\n",
       " 'rather': 16,\n",
       " 'decoding': 1,\n",
       " 'improvement': 4,\n",
       " 'ostensibly': 1,\n",
       " 'division': 2,\n",
       " 'digitized': 1,\n",
       " 'consumed': 1,\n",
       " 'Rajman': 1,\n",
       " 'Alenia': 1,\n",
       " 'requires': 16,\n",
       " 'hidden': 8,\n",
       " 'Corps': 2,\n",
       " 'workshops': 2,\n",
       " 'selects': 2,\n",
       " 'apple': 3,\n",
       " 'A.C.': 1,\n",
       " 'complicated': 3,\n",
       " 'queries': 3,\n",
       " 'Note': 9,\n",
       " 'disambiguation': 10,\n",
       " 'voice': 13,\n",
       " 'rewrite': 1,\n",
       " 'unit': 3,\n",
       " 'marketing': 1,\n",
       " 'year': 6,\n",
       " 'Das': 1,\n",
       " 'neighbors': 3,\n",
       " 'Noise': 1,\n",
       " 'Microphone': 1,\n",
       " 'estimated': 1,\n",
       " 'real-time': 2,\n",
       " 'Tom': 1,\n",
       " 'users': 9,\n",
       " 'Integration': 1,\n",
       " 'Significant': 1,\n",
       " 'detect': 1,\n",
       " 'wrong': 1,\n",
       " 'Ruth': 1,\n",
       " 'Terry': 1,\n",
       " 'formulation': 1,\n",
       " 'proven': 1,\n",
       " '26': 1,\n",
       " 'hyphenated': 1,\n",
       " 'Short': 1,\n",
       " 'placement': 1,\n",
       " 'Voice2Go': 1,\n",
       " 'conference': 2,\n",
       " 'access': 3,\n",
       " 'programs': 11,\n",
       " 'automates': 1,\n",
       " 'discors': 1,\n",
       " 'geography': 1,\n",
       " 'be': 237,\n",
       " 'audio': 2,\n",
       " 'has': 84,\n",
       " 'laws': 1,\n",
       " 'McCarthy': 1,\n",
       " 'frequencies': 2,\n",
       " 'Rate': 2,\n",
       " 'James': 4,\n",
       " 'error-prone': 1,\n",
       " 'have': 104,\n",
       " '150,000': 1,\n",
       " 'false': 2,\n",
       " 'cutoff': 1,\n",
       " 'occurs': 3,\n",
       " 'companies': 2,\n",
       " 'boolean': 1,\n",
       " 'Wodak': 1,\n",
       " 'agrees': 1,\n",
       " 'representative': 1,\n",
       " 'mechanisms': 2,\n",
       " 'libraries': 2,\n",
       " 'Unicode': 1,\n",
       " 'Telephony': 1,\n",
       " 'ratings': 9,\n",
       " 'Larry': 2,\n",
       " 'depths': 1,\n",
       " 'parameters': 4,\n",
       " 'aural': 1,\n",
       " 'pulled': 1,\n",
       " 'end': 8,\n",
       " 'together': 8,\n",
       " 'per': 4,\n",
       " 'dispense': 1,\n",
       " 'Germany': 2,\n",
       " 'Computing': 2,\n",
       " 'human-generated': 2,\n",
       " 'inadequate': 1,\n",
       " '1979': 1,\n",
       " 'mental': 3,\n",
       " 'parsed': 4,\n",
       " 'contains': 10,\n",
       " 'Jan': 1,\n",
       " 'relaxed': 1,\n",
       " 'recommendation': 2,\n",
       " 'applies': 7,\n",
       " 'begin': 3,\n",
       " 'sixty': 2,\n",
       " 'cache': 1,\n",
       " 'Vocalizations': 1,\n",
       " 'truck': 1,\n",
       " 'Deborah': 2,\n",
       " 'Polar': 1,\n",
       " 'word-forms': 1,\n",
       " 'pruned': 1,\n",
       " 'Press': 1,\n",
       " 'uttered': 3,\n",
       " 'ultraviolet': 1,\n",
       " 'OnStar': 1,\n",
       " 'confirmed': 1,\n",
       " 'ambitious': 1,\n",
       " 'reported': 5,\n",
       " 'silence': 1,\n",
       " 'SPHINX': 1,\n",
       " 'modified': 1,\n",
       " 'bunch': 2,\n",
       " 'incorporate': 1,\n",
       " 'phenomenon': 5,\n",
       " 'proceeds': 1,\n",
       " 'door': 4,\n",
       " 'IE': 3,\n",
       " 'Sparkle': 1,\n",
       " 'expensive': 7,\n",
       " 'prior': 3,\n",
       " '17': 1,\n",
       " 'preclude': 1,\n",
       " 'marker': 1,\n",
       " 'paying': 1,\n",
       " 'option': 1,\n",
       " 'humans': 12,\n",
       " 'bi-directional': 1,\n",
       " 'their': 34,\n",
       " 'Flow': 1,\n",
       " 'estimation': 1,\n",
       " 'Aermacchi': 1,\n",
       " 'Because': 2,\n",
       " 'ontologies': 6,\n",
       " 'arm': 1,\n",
       " 'granted': 1,\n",
       " 'processed': 6,\n",
       " 'even': 27,\n",
       " 'indirect': 1,\n",
       " 'unlike': 1,\n",
       " 'Japanese': 8,\n",
       " 'follow-the-bouncing-ball': 1,\n",
       " 'Similarly': 1,\n",
       " 'meteorologist': 1,\n",
       " 'concentrates': 1,\n",
       " 'Importance': 1,\n",
       " 'clarify': 1,\n",
       " 'far': 8,\n",
       " 'Northern': 3,\n",
       " 'painstakingly': 1,\n",
       " 'Another': 13,\n",
       " 'grid': 1,\n",
       " 'driving': 1,\n",
       " 'breathing': 1,\n",
       " 'rated': 1,\n",
       " '1956': 1,\n",
       " 'e.g.': 56,\n",
       " 'Determine': 1,\n",
       " 'setting': 5,\n",
       " '23': 1,\n",
       " 'Questions': 1,\n",
       " 'Avionics': 1,\n",
       " 'US': 7,\n",
       " 'In': 105,\n",
       " 'interactions': 1,\n",
       " \"d'évaluation\": 1,\n",
       " 'trade': 2,\n",
       " 'Words': 4,\n",
       " 'Starting': 1,\n",
       " 'successively': 1,\n",
       " 'HAMS': 1,\n",
       " 'entering': 2,\n",
       " 'numeric': 1,\n",
       " 'revolution': 1,\n",
       " 'Unsupervised': 6,\n",
       " 'facemask': 1,\n",
       " 'cryptanalyst': 1,\n",
       " 'moderate': 5,\n",
       " 'early': 10,\n",
       " 'to': 753,\n",
       " 'summarizing': 1,\n",
       " 'especially': 15,\n",
       " 'from': 104,\n",
       " 'machine-aided': 1,\n",
       " 'conducted': 5,\n",
       " 'Journal': 3,\n",
       " 'computed': 2,\n",
       " 'iteration': 1,\n",
       " 'professional': 1,\n",
       " 'give': 4,\n",
       " 'studied': 1,\n",
       " 'Booth': 1,\n",
       " 'tones': 1,\n",
       " 'identified': 5,\n",
       " 'Brazil': 1,\n",
       " 'envelope': 1,\n",
       " 'ideas': 4,\n",
       " '1954': 3,\n",
       " 'bought': 1,\n",
       " 'Even': 1,\n",
       " 'Conferences': 2,\n",
       " 'diagramming': 2,\n",
       " 'CCD': 1,\n",
       " '2,026,329': 1,\n",
       " 'library': 2,\n",
       " 'advanced': 5,\n",
       " 'TextRank': 14,\n",
       " 'Perhaps': 1,\n",
       " 'least': 5,\n",
       " 'k': 1,\n",
       " 'Lichtenstein': 1,\n",
       " 'outside': 2,\n",
       " 'precisely': 1,\n",
       " 'sensible': 1,\n",
       " 'orally': 1,\n",
       " 'addressed': 2,\n",
       " 'first-order': 1,\n",
       " 'controversial': 1,\n",
       " 'corpus': 31,\n",
       " 'suitability': 2,\n",
       " 'final': 9,\n",
       " 'terms': 13,\n",
       " 'emotion': 1,\n",
       " 'dictionary': 7,\n",
       " 'exceptions': 1,\n",
       " 'acquiring': 1,\n",
       " 'acoustic': 6,\n",
       " 'classifies': 1,\n",
       " 'remains': 4,\n",
       " 'dataset': 1,\n",
       " 'induction': 2,\n",
       " 'series': 8,\n",
       " 'form': 20,\n",
       " 'Wetherell': 1,\n",
       " 'LL': 2,\n",
       " 'http:\\\\/\\\\/haydn.isi.edu\\\\/ROUGE\\\\/': 1,\n",
       " 'sentiments': 1,\n",
       " 'declared': 2,\n",
       " 'sophisticated': 7,\n",
       " 'direction': 3,\n",
       " 'statistics': 8,\n",
       " 'developed': 26,\n",
       " 'equal': 1,\n",
       " 'S.': 2,\n",
       " 'Spoken': 1,\n",
       " 'study': 4,\n",
       " 'corresponds': 1,\n",
       " 'unrealistically': 1,\n",
       " 'they': 40,\n",
       " 'UMLS': 1,\n",
       " 'NNS': 1,\n",
       " 'guided': 1,\n",
       " 'underlie': 1,\n",
       " 'Inuit': 1,\n",
       " 'fine-grained': 1,\n",
       " 'subtypes': 1,\n",
       " 'movies': 1,\n",
       " 'run': 5,\n",
       " 'ways': 8,\n",
       " 'F-16': 2,\n",
       " 'delimiter': 1,\n",
       " 'receivers': 1,\n",
       " 'annual': 2,\n",
       " 'resulted': 2,\n",
       " 'German': 4,\n",
       " 'emergence': 1,\n",
       " 'giving': 2,\n",
       " 'grammatical': 11,\n",
       " 'predict': 6,\n",
       " '2009': 3,\n",
       " 'where': 35,\n",
       " 'with': 183,\n",
       " '!': 1,\n",
       " 'got': 1,\n",
       " 'accuracy': 31,\n",
       " 'evident': 2,\n",
       " 'scaling': 1,\n",
       " 'Verschueren': 1,\n",
       " 'official': 1,\n",
       " 'Please': 3,\n",
       " 'suffix': 1,\n",
       " 'derive': 2,\n",
       " 'planning': 2,\n",
       " 'Wilensky': 2,\n",
       " 'offs': 1,\n",
       " 'Department': 1,\n",
       " 'SourceForge': 1,\n",
       " 'color': 1,\n",
       " 'attempts': 6,\n",
       " 'active': 2,\n",
       " 'Tagging': 1,\n",
       " 'Finally': 1,\n",
       " 'Tagset': 1,\n",
       " 'variety': 8,\n",
       " 'summarise': 3,\n",
       " 'optimizes': 1,\n",
       " 'why': 7,\n",
       " 'extended': 1,\n",
       " 'do': 26,\n",
       " 'smaller': 7,\n",
       " '1960s': 3,\n",
       " 'particular': 13,\n",
       " 'informational': 2,\n",
       " 'eliminate': 2,\n",
       " 'emoticons': 1,\n",
       " 'element': 1,\n",
       " 'automation': 1,\n",
       " 'large-scale': 1,\n",
       " 'registry': 1,\n",
       " 'Hybrid': 2,\n",
       " '7': 7,\n",
       " 'debated': 1,\n",
       " 'Several': 3,\n",
       " 'traditionally': 2,\n",
       " 'effective': 6,\n",
       " 'Eurofighter': 1,\n",
       " 'around': 8,\n",
       " 'issue': 8,\n",
       " 'bore': 1,\n",
       " 'Scotland': 5,\n",
       " 'stopwords': 1,\n",
       " 'EAGLi': 1,\n",
       " 'Rubin': 1,\n",
       " 'HMT': 1,\n",
       " 'look-up': 1,\n",
       " 'Workshop': 1,\n",
       " 'readers': 2,\n",
       " 'practically': 1,\n",
       " 'assigning': 1,\n",
       " 'features\\\\/aspects': 1,\n",
       " 'meanings': 4,\n",
       " 'achieves': 2,\n",
       " 'denote': 2,\n",
       " 'Consider': 2,\n",
       " 'subsystem': 1,\n",
       " 'output': 26,\n",
       " 'informativeness': 3,\n",
       " 'shed': 1,\n",
       " 'ears': 1,\n",
       " 'Intuitively': 1,\n",
       " 'more': 95,\n",
       " 'operational': 1,\n",
       " 'diverse': 2,\n",
       " 'unless': 1,\n",
       " 'robust': 4,\n",
       " 'learned': 5,\n",
       " 'worlds': 1,\n",
       " 'First': 1,\n",
       " 'account': 3,\n",
       " 'bilingual': 2,\n",
       " 'Telephone': 1,\n",
       " 'leading': 2,\n",
       " 'dry': 1,\n",
       " 'Q&A': 1,\n",
       " 'Response': 1,\n",
       " 'compute': 2,\n",
       " 'USMC': 1,\n",
       " 'Beigi': 1,\n",
       " 'Overview': 2,\n",
       " 'multileveled': 1,\n",
       " 'Computationally': 1,\n",
       " 'Reinvestment': 1,\n",
       " 'represented': 6,\n",
       " 'OCR-A': 1,\n",
       " 'order': 14,\n",
       " 'reputations': 1,\n",
       " 'telephone': 2,\n",
       " 'content': 12,\n",
       " 'articles': 8,\n",
       " '\\\\/': 3,\n",
       " 'workday': 1,\n",
       " 'War': 1,\n",
       " 'Deep': 1,\n",
       " 'stochastic': 8,\n",
       " 'try': 3,\n",
       " 'subset': 3,\n",
       " '<verb>': 1,\n",
       " 'broken': 5,\n",
       " 'Scope': 1,\n",
       " 'generating': 5,\n",
       " 'displaced': 1,\n",
       " 'reasoning': 7,\n",
       " 'those': 22,\n",
       " 'McDonald': 1,\n",
       " 'flow': 1,\n",
       " 'Wall': 2,\n",
       " 'Success': 1,\n",
       " 'paraphrases': 1,\n",
       " 'G': 1,\n",
       " 'VTLN': 1,\n",
       " 'infer': 1,\n",
       " 'comprehend': 1,\n",
       " 'Nunan': 1,\n",
       " 'man': 1,\n",
       " ...}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
